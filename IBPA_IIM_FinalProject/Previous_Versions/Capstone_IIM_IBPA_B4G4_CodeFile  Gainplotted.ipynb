{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Problem Statement:\n",
    "A group of customers were given an offer in person that they can get a loan at discounted rate and\n",
    "processing fee will be waived off. A pilot campaign was conducted to get response from customers\n",
    "whether they are interested in taking out a loan or not. Response was recorded and data was collected.\n",
    "\n",
    "### Task List\n",
    "\n",
    "- [x] Build a model to predict whether customers will be interested in taking out a loan or not.\n",
    "- [x] Identifying features which are most important\n",
    "- [x] In case of black box models e.g. Random forest use SHAP, LIME to figure out features affecting the target variable\n",
    "- [x] Try Unsupervised clustering models\n",
    "- [x] Remove Unnecessary Models from the File\n",
    "- [x] Generate synthetic data for model.\n",
    "- [x] Approaching a customer has costs involved with it, hence find the profitable segments so that more customized marketing can be done.\n",
    "- [x] Need to write inferences what is going on\n",
    "- [x] Matrix evaluation for all 20% above models \n",
    "- [x] KS Scaling\n",
    "- [x] Variance Inflation Factor (VIF)\n",
    "- [x] Bucketing Age and SCR\n",
    "- [x] Business Output\n",
    "\n",
    "Variables involved: `Customer_id`, `Age`, `Gender`, `Balance`, `Occupation`, `No of Credit transaction`, `SCR`, `Holding period`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Complex Variables\n",
    "\n",
    "\n",
    "- `Holding Period` (How long the customer is able to hold the money in his account.. So, if they have some existing expenses like a loan EMI or any other monthly expense which gets deducted, usually the first week of every month, hence it makes the balance in the account lower during initial days of the month itself.Higher the holding period, more stable their money is in the account.)\n",
    "\n",
    "- `SCR` SCR is a score given to a customer for a particular product ( in this case loan ) based on certain parameters, to know whether how likely that customer is to buy that product.. so, higher the score, higher the probability, the customer will buy it. SCR propensity of a customer to respond to a digital marketing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  HOLDING PERIOD Vs AVG BALANCE\n",
    "\n",
    "1. The avg holding period and avg balance tend to show high collinearity as they are directly proportional and it can be verified from \"Misc_Dash\".\n",
    "\n",
    "2. Self employed class in both genders were able to hold money in their account for a long time resulting in high balance amount.\n",
    "\n",
    "##### Which Category of Customers Tend to opt for Loans?\n",
    "\n",
    "Customers with the below traits tend to be inclined towards opting for a loan;\n",
    "\n",
    "1. Females who own small business/self-owned (SENP) business show higher SCR.\n",
    "\n",
    "2. Males who are self employed (SELF-EMP) show higher SCR .\n",
    "\n",
    "3. High SCR's but least holding period i.e. who tend to have EMI's or other deductions from their account.\n",
    "\n",
    "4. Higher Avg credit transactions shows that the customer is more likely to opt for a loan. As Credit transactions show direct proportionality to SCR values.\n",
    "\n",
    "##### Final Conclusions\n",
    "\n",
    "1. From the given data it can be observed that in Females Self Employed tend to be the early bread earners whereas in case of Males Small Business owners tend to be the early bread earners.\n",
    "\n",
    "2. For both the genders higher avg balance amount is observed in the accounts of Small business owners, second highest avg balance is observed for Professionals (PROF) category customers.\n",
    "\n",
    "\n",
    "##### Which Category of Customers TEND NOT TO OPT for Loans?\n",
    "\n",
    "1. In Males, Salaried & Professional class employees tend to not opt for loans as they must have constant inflow of cash.\n",
    "\n",
    "2. In Females, Professional class employees tend to not opt for loans.\n",
    "\n",
    "3. In both the genders, customers showing higher holding period tend to not opt for loans as there are less deductions over long time periods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, roc_curve, auc, plot_roc_curve\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Data from CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Model_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Balance = data.Balance.astype('int32') #Truncating decimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Balance.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Gender` and `Occupation` are categorical varibles stored as object type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------Start of Exploratory Data Analysis-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.corr(), annot=True, square=True) # No strong correlations seen overall\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Inferences: \n",
    "\n",
    "- `TARGET` does show maximum correlation w.r.t `No_OF_CR_TXNS` among other variables. Remaining correlations have to be visualized in order to understand if there's any sort of trend in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(data, hue='Target')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inferences from Pair-Plot: \n",
    "\n",
    "- People who tend to opt for loan have less `BALANCE` w.r.t people not buying loan.\n",
    "- People having higher `BALANCE` tend to be in between 35-50 years of `AGE`.\n",
    "- People having less `BALANCE` tend to show more interest towards loans i.e. higher `SCR` values.\n",
    "- People having less `BALANCE` tend to have higher `No of Credit transactions` opt for loans.\n",
    "- People having less `BALANCE` have higher `HOLDING PERIOD` who opt for loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = data.Gender)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Observation: \n",
    "\n",
    "- Since `GENDER` = `\"OTHERS\"/\"O\"` has very less population size i.e. less than 1% of entire data hence can be omitted as an attribute from `GENDER` category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Gender.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Occupation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data.Gender[data.Gender== 'O'].index, axis = 0, inplace= True) # Removed 196 rows with `Gender` = 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Balance.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(data.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = data.Occupation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Inferences: \n",
    "\n",
    "- The data consists mostly of `Salaried` category employees, whereas `Business Owners` and `Professionals` occupy the same strength in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=data.Target, hue=data.Occupation) ## Self employed are much more likely to take loans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inferences: \n",
    "\n",
    "- Most people who opted for loans tend to be either `Self-Employed` or `Small businesses` whereas `Salaried` people showed quite less interest in taking up loans since they had fixed income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data, col='Occupation', hue=\"Gender\")\n",
    "plt.grid(True)\n",
    "g.map(sns.countplot, \"Gender\", alpha=1)\n",
    "g.add_legend()\n",
    "plt.grid((False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Inferences: \n",
    "\n",
    "- Most of the `Males` tend to be either in `Salaried` employee class (nearly 85%) or `working professionals` (nearly 70%) whereas most `Women` (nearly 90%) tend to start-up their own `business's` and manage them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(data.No_OF_CR_TXNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.No_OF_CR_TXNS.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x=data.No_OF_CR_TXNS)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Inferences: \n",
    "\n",
    "- The average `No. of Credit Transactions` tend to be in between 10 and 20. Whereas very few transactions tend to be in the number of 30-50.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(data[data.No_OF_CR_TXNS==0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.drop(index=data[data.No_OF_CR_TXNS==0].index, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.displot(data.SCR, kind = 'kde')\n",
    "sns.distplot(data.SCR)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Inferences: \n",
    "\n",
    "- A uniform distribution can be observed for `SCR` and no skewness is found in the given data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.SCR.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(data.Holding_Period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------End of Exploratory Data Analysis-------------------------------------------------------\n",
    "-----------\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretty Report Printing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class for pretty printing\n",
    "class color:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'\n",
    "    \n",
    "# function for validation on test data   \n",
    "def classification_report(y_true, y_prediction, type_of_data='Enter Over/Under/Original sampled', type_of_classifier='ClassifierName'):\n",
    "    \"\"\"Print Classification report\"\"\"\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_prediction)\n",
    "    precision = precision_score(y_true, y_prediction)\n",
    "    recall = recall_score(y_true, y_prediction)\n",
    "    f1 = f1_score(y_true, y_prediction)\n",
    "    \n",
    "    print('Classification Report on Testing Data:\\n'+ color.BOLD + type_of_data, 'data\\n'+color.END+color.RED+color.BOLD+type_of_classifier,'Classifier'+color.END+color.END)\n",
    "    print()\n",
    "    print('---------------------------------------')\n",
    "    print(color.BOLD + 'Recall: %s' %recall + color.END)\n",
    "    print('Precision: %s' %precision)\n",
    "    print('F1 score: %s' %f1)\n",
    "    print('Accuracy: %s' %accuracy)\n",
    "    print('---------------------------------------')\n",
    "    print()\n",
    "\n",
    "\n",
    "# A function for cross-validation report    \n",
    "def cross_val_report(classifier, train_data, train_label, cv=10, scoring=['recall','precision', 'f1','accuracy']):\n",
    "    \n",
    "    score = cross_validate(classifier, train_data, train_label, cv=cv, scoring= scoring)\n",
    "    recall = np.mean(score['test_recall'])\n",
    "    precision = np.mean(score['test_precision'])\n",
    "    f1 = np.mean(score['test_f1'])\n",
    "    accuracy= np.mean(score['test_accuracy'])\n",
    "    print('Cross Validation Report')\n",
    "    print(color.BOLD + 'Recall: %s' %recall + color.END)\n",
    "    print('Precision: %s' %precision)\n",
    "    print('F1: %s' %f1)\n",
    "    print('Accuracy: %s' %accuracy)\n",
    "    print()\n",
    "    print(\"*Mean values presented\")\n",
    "    print('---------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the first set of training and test data on imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data, columns=['Gender','Occupation'], drop_first = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a model with Original Unbalanced data and measuring metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_original = df.iloc[:,1:]\n",
    "y_original = df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_original.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(X_original,y_original, shuffle = ['True'], stratify=y_original)\n",
    "X_test_orig.reset_index(inplace = True, drop=True)\n",
    "y_test_orig.reset_index(inplace = True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------Start of Model Exploration---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create undersampled data and fit a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_under_train, y_under_train = NearMiss().fit_resample(X_train_orig, y_train_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.Target==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_under_train.shape, y_under_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Model on  an oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_over_train, y_over_train = SMOTE().fit_resample(X_train_orig, y_train_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original:     \"+color.BOLD+ \"X_original,y_original\"+color.END+\"::  X_train_orig, X_test_orig, y_train_orig, y_test_orig\")\n",
    "print()\n",
    "print(\"Undersampled:\"+color.BOLD+ \" X_under, y_under\"+color.END+\"     ::  X_under_train, y_under_train\")\n",
    "print()\n",
    "print(\"Oversampled:\"+color.BOLD+ \"  X_over, y_over\"+color.END+\"       ::  X_over_train, y_over_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above datasets can be better sampled by adjusting hyper-parameters of NearMiss and SMOTE, or other methods of sampling could be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier - Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf0 = RandomForestClassifier()\n",
    "clf_rf0.fit(X_train_orig, y_train_orig)\n",
    "y_predict= clf_rf0.predict(X_test_orig)\n",
    "classification_report(y_test_orig, y_predict, 'Original', 'Random Forest')\n",
    "\n",
    "cross_val_report(clf_rf0, X_under_train, y_under_train)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(15,5))\n",
    "plot_roc_curve(clf_rf0, X_test_orig, y_test_orig, ax=axs[0])\n",
    "plot_confusion_matrix(clf_rf0, X_test_orig, y_test_orig, cmap='BuPu', ax=axs[1])\n",
    "\n",
    "proba = clf_rf0.predict_proba(X_test_orig)[:,1]\n",
    "axs[2].hist(proba)\n",
    "axs[2].set_title('Probablity of Target=1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_orig, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_partial_dependence(clf_rf0, X_test_orig, X_test_orig.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.Series(clf_rf0.feature_importances_, index=X_test_orig.columns)\n",
    "   .nlargest(4)\n",
    "   .plot(kind='bar'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inferences: \n",
    "\n",
    "- The prominent features are: `SCR`,`BALANCE`,`No_OF_CR_TXNS`,`Holding_Period`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFE Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RFE(RandomForestClassifier(), n_features_to_select=4)\n",
    "rfe = rfe.fit(X_over_train, y_over_train)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_over_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inferences:\n",
    "\n",
    "- RFE algorithm decided prominent features: `SCR`,`BALANCE`,`No_OF_CR_TXNS`,`Holding_Period`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_indices = np.where(X_train_orig.dtypes != np.float)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest Classifier - Undersampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orig.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf1 = RandomForestClassifier()\n",
    "clf_rf1.fit(X_under_train, y_under_train)\n",
    "y_predict= clf_rf1.predict(X_test_orig)\n",
    "classification_report(y_test_orig, y_predict, 'Undersampled', 'Random Forest')\n",
    "cross_val_report(clf_rf1, X_under_train, y_under_train)\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(15,5))\n",
    "plot_roc_curve(clf_rf1, X_test_orig, y_test_orig, ax=axs[0])\n",
    "plot_confusion_matrix(clf_rf1, X_test_orig, y_test_orig, cmap='BuPu', ax=axs[1])\n",
    "\n",
    "proba = clf_rf1.predict_proba(X_test_orig)[:,1]\n",
    "axs[2].hist(proba)\n",
    "axs[2].set_title('Probablity of Target=1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_orig, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank Ordering Stats for Random Forest - Undersampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_df = pd.DataFrame(proba, columns=['Probablity'])\n",
    "proba_df['present_decile'] = pd.qcut(proba_df.Probablity, 10, labels=[str(i+1) for i in range(10)])\n",
    "proba_df.present_decile = proba_df.present_decile.astype(int)\n",
    "\n",
    "proba_df['response_test'] = y_test_orig\n",
    "proba_df['response_model'] = proba_df['Probablity'].apply(lambda x: 0 if x<=0.5 else 1)\n",
    "proba_df['correct_loan_prediction'] = 0\n",
    "for ind, row in proba_df.iterrows():\n",
    "    if row['response_test'] == row['response_model'] == 1:\n",
    "        proba_df.loc[ind, 'correct_loan_prediction'] =1\n",
    "\n",
    "\n",
    "ks_table = pd.DataFrame({'Decile':[j for j in range(10,0,-1)]})\n",
    "\n",
    "ks_table['base'] =0\n",
    "ks_table['responses'] =0\n",
    "ks_table['non_responses'] =0\n",
    "for ind, row in ks_table.iterrows():\n",
    "    ks_table.loc[ind, 'base'] = proba_df[proba_df.present_decile==row['Decile']].shape[0]\n",
    "    \n",
    "    try:\n",
    "        correct_loan_prediction1 = proba_df[proba_df.present_decile==row['Decile']].correct_loan_prediction.value_counts()[1]\n",
    "    except:\n",
    "        correct_loan_prediction1 = 0\n",
    "        \n",
    "    ks_table.loc[ind, 'responses'] = correct_loan_prediction1\n",
    "    \n",
    "ks_table['non_responses'] = ks_table['base'] - ks_table['responses']\n",
    "    \n",
    "ks_table['resp_rate'] = ks_table['responses']/ks_table['base']*100\n",
    "ks_table['non_resp_rate'] = ks_table['non_responses']/ks_table['base']*100\n",
    "\n",
    "ks_table['cum_base'] = ks_table.base.cumsum()\n",
    "ks_table['cum_resp'] = ks_table.responses.cumsum()\n",
    "ks_table['cum_non_resp'] = ks_table.non_responses.cumsum()\n",
    "\n",
    "ks_table['cum_resp%'] = ks_table['cum_resp']/ks_table['cum_resp'].max()*100\n",
    "ks_table['cum_non_resp%'] = ks_table['cum_non_resp']/ks_table['cum_non_resp'].max()*100\n",
    "ks_table['ks'] = ks_table['cum_resp%']-ks_table['cum_non_resp%']\n",
    "\n",
    "ks_table['na_label'] = ks_table['cum_resp']/ks_table['cum_base']*100\n",
    "ks_table['lift'] = ks_table['na_label']/(100*ks_table['cum_resp'].max()/ks_table['cum_base'].max())\n",
    "\n",
    "ks_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gain Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(1,11)],ks_table['cum_resp%'], label = 'Targeted Response')\n",
    "plt.plot([i for i in range(1,11)], np.arange(0, 110, 10)[1:], label = 'Random approach')\n",
    "\n",
    "plt.xticks(np.arange(1, 11), labels=[(str(i)+'0%') for i in list(range(0,11))])\n",
    "plt.yticks(np.arange(0, 110, 10), labels=[(str(i)+'0%') for i in list(range(0,11))])\n",
    "\n",
    "plt.title('Gain Chart')\n",
    "plt.ylabel('Cumulative Percentage of Responders Captured')\n",
    "plt.xlabel('Population')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lift Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(1,11)],ks_table.lift*100, label = 'Targeted Response')\n",
    "plt.plot([i for i in range(1,11)], [100, 100, 100, 100, 100, 100, 100, 100, 100, 100], label = 'Random approach')\n",
    "\n",
    "plt.xticks(np.arange(1, 11), labels=[(str(i)) for i in list(range(1,11))])\n",
    "plt.yticks(np.arange(0, 900, 100), labels=[(str(i)+'00%') for i in list(range(0,11))])\n",
    "\n",
    "plt.title('Lift Chart')\n",
    "plt.ylabel('Lift%')\n",
    "plt.xlabel('Decile')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KS chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(1,11)],ks_table['cum_resp%'], label = 'Positive Response')\n",
    "plt.plot([i for i in range(1,11)],ks_table['cum_non_resp%'], label = 'Negative Response')\n",
    "# plt.plot([i for i in range(1,11)], np.arange(0, 110, 10)[1:], label = 'Negative')\n",
    "\n",
    "plt.xticks(np.arange(1, 11), labels=[(str(i)) for i in list(range(1,11))])\n",
    "plt.yticks(np.arange(0, 110, 10), labels=[(str(i)+'0%') for i in list(range(0,11))])\n",
    "\n",
    "plt.title('KS chart')\n",
    "plt.ylabel('Cumulative Responses')\n",
    "plt.xlabel('Deciles')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest Classifier - Oversampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf2 = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf2.fit(X_over_train, y_over_train)\n",
    "y_predict= clf_rf2.predict(X_test_orig)\n",
    "classification_report(y_test_orig, y_predict, 'Oversampled', 'Random Forest')\n",
    "\n",
    "cross_val_report(clf_rf2, X_over_train, y_over_train)\n",
    "\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(15,5))\n",
    "plot_roc_curve(clf_rf2, X_test_orig, y_test_orig, ax=axs[0])\n",
    "plot_confusion_matrix(clf_rf2, X_test_orig, y_test_orig, cmap='BuPu', ax=axs[1])\n",
    "\n",
    "proba = clf_rf2.predict_proba(X_test_orig)[:,1]\n",
    "axs[2].hist(proba)\n",
    "axs[2].set_title('Probablity of Target=1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_orig, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.Series(clf_rf2.feature_importances_, index=X_test_orig.columns)\n",
    "   .nlargest(4)\n",
    "   .plot(kind='barh'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank Ordering Stats for Random Forest - Oversampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_df = pd.DataFrame(proba, columns=['Probablity'])\n",
    "proba_df['present_decile'] = pd.qcut(proba_df.Probablity, 10, labels=[str(i+1) for i in range(10)])\n",
    "proba_df.present_decile = proba_df.present_decile.astype(int)\n",
    "\n",
    "proba_df['response_test'] = y_test_orig\n",
    "proba_df['response_model'] = proba_df['Probablity'].apply(lambda x: 0 if x<=0.5 else 1)\n",
    "proba_df['correct_loan_prediction'] = 0\n",
    "for ind, row in proba_df.iterrows():\n",
    "    if row['response_test'] == row['response_model'] == 1:\n",
    "        proba_df.loc[ind, 'correct_loan_prediction'] =1\n",
    "\n",
    "\n",
    "ks_table = pd.DataFrame({'Decile':[j for j in range(10,0,-1)]})\n",
    "\n",
    "ks_table['base'] =0\n",
    "ks_table['responses'] =0\n",
    "ks_table['non_responses'] =0\n",
    "for ind, row in ks_table.iterrows():\n",
    "    ks_table.loc[ind, 'base'] = proba_df[proba_df.present_decile==row['Decile']].shape[0]\n",
    "    \n",
    "    try:\n",
    "        correct_loan_prediction1 = proba_df[proba_df.present_decile==row['Decile']].correct_loan_prediction.value_counts()[1]\n",
    "    except:\n",
    "        correct_loan_prediction1 = 0\n",
    "        \n",
    "    ks_table.loc[ind, 'responses'] = correct_loan_prediction1\n",
    "    \n",
    "ks_table['non_responses'] = ks_table['base'] - ks_table['responses']\n",
    "    \n",
    "ks_table['resp_rate'] = ks_table['responses']/ks_table['base']*100\n",
    "ks_table['non_resp_rate'] = ks_table['non_responses']/ks_table['base']*100\n",
    "\n",
    "ks_table['cum_base'] = ks_table.base.cumsum()\n",
    "ks_table['cum_resp'] = ks_table.responses.cumsum()\n",
    "ks_table['cum_non_resp'] = ks_table.non_responses.cumsum()\n",
    "\n",
    "ks_table['cum_resp%'] = ks_table['cum_resp']/ks_table['cum_resp'].max()*100\n",
    "ks_table['cum_non_resp%'] = ks_table['cum_non_resp']/ks_table['cum_non_resp'].max()*100\n",
    "ks_table['ks'] = ks_table['cum_resp%']-ks_table['cum_non_resp%']\n",
    "\n",
    "ks_table['na_label'] = ks_table['cum_resp']/ks_table['cum_base']*100\n",
    "ks_table['lift'] = ks_table['na_label']/(100*ks_table['cum_resp'].max()/ks_table['cum_base'].max())\n",
    "\n",
    "ks_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gain Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(1,11)],ks_table['cum_resp%'], label = 'Targeted Response')\n",
    "plt.plot([i for i in range(1,11)], np.arange(0, 110, 10)[1:], label = 'Random approach')\n",
    "\n",
    "plt.xticks(np.arange(1, 11), labels=[(str(i)+'0%') for i in list(range(0,11))])\n",
    "plt.yticks(np.arange(0, 110, 10), labels=[(str(i)+'0%') for i in list(range(0,11))])\n",
    "\n",
    "plt.title('Gain Chart')\n",
    "plt.ylabel('Cumulative Percentage of Responders Captured')\n",
    "plt.xlabel('Population')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lift Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(1,11)],ks_table.lift*100, label = 'Targeted Response')\n",
    "plt.plot([i for i in range(1,11)], [100, 100, 100, 100, 100, 100, 100, 100, 100, 100], label = 'Random approach')\n",
    "\n",
    "plt.xticks(np.arange(1, 11), labels=[(str(i)) for i in list(range(1,11))])\n",
    "plt.yticks(np.arange(0, 900, 100), labels=[(str(i)+'00%') for i in list(range(0,11))])\n",
    "\n",
    "plt.title('Lift Chart')\n",
    "plt.ylabel('Lift%')\n",
    "plt.xlabel('Decile')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KS chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(1,11)],ks_table['cum_resp%'], label = 'Positive Response')\n",
    "plt.plot([i for i in range(1,11)],ks_table['cum_non_resp%'], label = 'Negative Response')\n",
    "# plt.plot([i for i in range(1,11)], np.arange(0, 110, 10)[1:], label = 'Negative')\n",
    "\n",
    "plt.xticks(np.arange(1, 11), labels=[(str(i)) for i in list(range(1,11))])\n",
    "plt.yticks(np.arange(0, 110, 10), labels=[(str(i)+'0%') for i in list(range(0,11))])\n",
    "\n",
    "plt.title('KS chart')\n",
    "plt.ylabel('Cumulative Responses')\n",
    "plt.xlabel('Deciles')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression - Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr0 = LogisticRegression(max_iter=1000)\n",
    "lr0.fit(X_train_orig, y_train_orig)\n",
    "y_predict= lr0.predict(X_test_orig)\n",
    "classification_report(y_test_orig, y_predict, 'Original', 'Logistic Regression')\n",
    "\n",
    "cross_val_report(lr0, X_under_train, y_under_train)\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(15,5))\n",
    "plot_roc_curve(lr0, X_test_orig, y_test_orig, ax=axs[0])\n",
    "plot_confusion_matrix(lr0, X_test_orig, y_test_orig, cmap='BuPu', ax=axs[1])\n",
    "\n",
    "proba = lr0.predict_proba(X_test_orig)[:,1]\n",
    "axs[2].hist(proba)\n",
    "axs[2].set_title('Probablity of Target=1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_orig, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank Ordering Stats for Logistic Regression - Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_df = pd.DataFrame(proba, columns=['Probablity'])\n",
    "proba_df['present_decile'] = pd.qcut(proba_df.Probablity, 10, labels=[str(i+1) for i in range(10)])\n",
    "proba_df.present_decile = proba_df.present_decile.astype(int)\n",
    "\n",
    "proba_df['response_test'] = y_test_orig\n",
    "proba_df['response_model'] = proba_df['Probablity'].apply(lambda x: 0 if x<=0.5 else 1)\n",
    "proba_df['correct_loan_prediction'] = 0\n",
    "for ind, row in proba_df.iterrows():\n",
    "    if row['response_test'] == row['response_model'] == 1:\n",
    "        proba_df.loc[ind, 'correct_loan_prediction'] =1\n",
    "\n",
    "\n",
    "ks_table = pd.DataFrame({'Decile':[j for j in range(10,0,-1)]})\n",
    "\n",
    "ks_table['base'] =0\n",
    "ks_table['responses'] =0\n",
    "ks_table['non_responses'] =0\n",
    "for ind, row in ks_table.iterrows():\n",
    "    ks_table.loc[ind, 'base'] = proba_df[proba_df.present_decile==row['Decile']].shape[0]\n",
    "    \n",
    "    try:\n",
    "        correct_loan_prediction1 = proba_df[proba_df.present_decile==row['Decile']].correct_loan_prediction.value_counts()[1]\n",
    "    except:\n",
    "        correct_loan_prediction1 = 0\n",
    "        \n",
    "    ks_table.loc[ind, 'responses'] = correct_loan_prediction1\n",
    "    \n",
    "ks_table['non_responses'] = ks_table['base'] - ks_table['responses']\n",
    "    \n",
    "ks_table['resp_rate'] = ks_table['responses']/ks_table['base']*100\n",
    "ks_table['non_resp_rate'] = ks_table['non_responses']/ks_table['base']*100\n",
    "\n",
    "ks_table['cum_base'] = ks_table.base.cumsum()\n",
    "ks_table['cum_resp'] = ks_table.responses.cumsum()\n",
    "ks_table['cum_non_resp'] = ks_table.non_responses.cumsum()\n",
    "\n",
    "ks_table['cum_resp%'] = ks_table['cum_resp']/ks_table['cum_resp'].max()*100\n",
    "ks_table['cum_non_resp%'] = ks_table['cum_non_resp']/ks_table['cum_non_resp'].max()*100\n",
    "ks_table['ks'] = ks_table['cum_resp%']-ks_table['cum_non_resp%']\n",
    "\n",
    "ks_table['na_label'] = ks_table['cum_resp']/ks_table['cum_base']*100\n",
    "ks_table['lift'] = ks_table['na_label']/(100*ks_table['cum_resp'].max()/ks_table['cum_base'].max())\n",
    "\n",
    "ks_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gain Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(1,11)],ks_table['cum_resp%'], label = 'Targeted Response')\n",
    "plt.plot([i for i in range(1,11)], np.arange(0, 110, 10)[1:], label = 'Random approach')\n",
    "\n",
    "plt.xticks(np.arange(1, 11), labels=[(str(i)+'0%') for i in list(range(0,11))])\n",
    "plt.yticks(np.arange(0, 110, 10), labels=[(str(i)+'0%') for i in list(range(0,11))])\n",
    "\n",
    "plt.title('Gain Chart')\n",
    "plt.ylabel('Cumulative Percentage of Responders Captured')\n",
    "plt.xlabel('Population')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lift Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(1,11)],ks_table.lift*100, label = 'Targeted Response')\n",
    "plt.plot([i for i in range(1,11)], [100, 100, 100, 100, 100, 100, 100, 100, 100, 100], label = 'Random approach')\n",
    "\n",
    "plt.xticks(np.arange(1, 11), labels=[(str(i)) for i in list(range(1,11))])\n",
    "plt.yticks(np.arange(0, 900, 100), labels=[(str(i)+'00%') for i in list(range(0,11))])\n",
    "\n",
    "plt.title('Lift Chart')\n",
    "plt.ylabel('Lift%')\n",
    "plt.xlabel('Decile')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KS chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(1,11)],ks_table['cum_resp%'], label = 'Positive Response')\n",
    "plt.plot([i for i in range(1,11)],ks_table['cum_non_resp%'], label = 'Negative Response')\n",
    "# plt.plot([i for i in range(1,11)], np.arange(0, 110, 10)[1:], label = 'Negative')\n",
    "\n",
    "plt.xticks(np.arange(1, 11), labels=[(str(i)) for i in list(range(1,11))])\n",
    "plt.yticks(np.arange(0, 110, 10), labels=[(str(i)+'0%') for i in list(range(0,11))])\n",
    "\n",
    "plt.title('KS chart')\n",
    "plt.ylabel('Cumulative Responses')\n",
    "plt.xlabel('Deciles')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression - Undersampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1 = LogisticRegression(max_iter=100)\n",
    "lr1.fit(X_under_train, y_under_train)\n",
    "y_predict= lr1.predict(X_test_orig)\n",
    "classification_report(y_test_orig, y_predict, 'Undersampled', 'Logistic Regression')\n",
    "\n",
    "cross_val_report(lr1, X_under_train, y_under_train)\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(15,5))\n",
    "plot_roc_curve(lr1, X_test_orig, y_test_orig, ax=axs[0])\n",
    "plot_confusion_matrix(lr1, X_test_orig, y_test_orig, cmap='BuPu', ax=axs[1])\n",
    "\n",
    "proba = lr1.predict_proba(X_test_orig)[:,1]\n",
    "axs[2].hist(proba)\n",
    "axs[2].set_title('Probablity of Target=1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_orig, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank Ordering Stats for Logistic Regression - Undersampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_df = pd.DataFrame(proba, columns=['Probablity'])\n",
    "proba_df['present_decile'] = pd.qcut(proba_df.Probablity, 10, labels=[str(i+1) for i in range(10)])\n",
    "proba_df.present_decile = proba_df.present_decile.astype(int)\n",
    "\n",
    "proba_df['response_test'] = y_test_orig\n",
    "proba_df['response_model'] = proba_df['Probablity'].apply(lambda x: 0 if x<=0.5 else 1)\n",
    "proba_df['correct_loan_prediction'] = 0\n",
    "for ind, row in proba_df.iterrows():\n",
    "    if row['response_test'] == row['response_model'] == 1:\n",
    "        proba_df.loc[ind, 'correct_loan_prediction'] =1\n",
    "\n",
    "\n",
    "ks_table = pd.DataFrame({'Decile':[j for j in range(10,0,-1)]})\n",
    "\n",
    "ks_table['base'] =0\n",
    "ks_table['responses'] =0\n",
    "ks_table['non_responses'] =0\n",
    "for ind, row in ks_table.iterrows():\n",
    "    ks_table.loc[ind, 'base'] = proba_df[proba_df.present_decile==row['Decile']].shape[0]\n",
    "    \n",
    "    try:\n",
    "        correct_loan_prediction1 = proba_df[proba_df.present_decile==row['Decile']].correct_loan_prediction.value_counts()[1]\n",
    "    except:\n",
    "        correct_loan_prediction1 = 0\n",
    "        \n",
    "    ks_table.loc[ind, 'responses'] = correct_loan_prediction1\n",
    "    \n",
    "ks_table['non_responses'] = ks_table['base'] - ks_table['responses']\n",
    "    \n",
    "ks_table['resp_rate'] = ks_table['responses']/ks_table['base']*100\n",
    "ks_table['non_resp_rate'] = ks_table['non_responses']/ks_table['base']*100\n",
    "\n",
    "ks_table['cum_base'] = ks_table.base.cumsum()\n",
    "ks_table['cum_resp'] = ks_table.responses.cumsum()\n",
    "ks_table['cum_non_resp'] = ks_table.non_responses.cumsum()\n",
    "\n",
    "ks_table['cum_resp%'] = ks_table['cum_resp']/ks_table['cum_resp'].max()*100\n",
    "ks_table['cum_non_resp%'] = ks_table['cum_non_resp']/ks_table['cum_non_resp'].max()*100\n",
    "ks_table['ks'] = ks_table['cum_resp%']-ks_table['cum_non_resp%']\n",
    "\n",
    "ks_table['na_label'] = ks_table['cum_resp']/ks_table['cum_base']*100\n",
    "ks_table['lift'] = ks_table['na_label']/(100*ks_table['cum_resp'].max()/ks_table['cum_base'].max())\n",
    "\n",
    "ks_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gain Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(1,11)],ks_table['cum_resp%'], label = 'Targeted Response')\n",
    "plt.plot([i for i in range(1,11)], np.arange(0, 110, 10)[1:], label = 'Random approach')\n",
    "\n",
    "plt.xticks(np.arange(1, 11), labels=[(str(i)+'0%') for i in list(range(0,11))])\n",
    "plt.yticks(np.arange(0, 110, 10), labels=[(str(i)+'0%') for i in list(range(0,11))])\n",
    "\n",
    "plt.title('Gain Chart')\n",
    "plt.ylabel('Cumulative Percentage of Responders Captured')\n",
    "plt.xlabel('Population')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lift Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(1,11)],ks_table.lift*100, label = 'Targeted Response')\n",
    "plt.plot([i for i in range(1,11)], [100, 100, 100, 100, 100, 100, 100, 100, 100, 100], label = 'Random approach')\n",
    "\n",
    "plt.xticks(np.arange(1, 11), labels=[(str(i)) for i in list(range(1,11))])\n",
    "plt.yticks(np.arange(0, 900, 100), labels=[(str(i)+'00%') for i in list(range(0,11))])\n",
    "\n",
    "plt.title('Lift Chart')\n",
    "plt.ylabel('Lift%')\n",
    "plt.xlabel('Decile')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KS chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(1,11)],ks_table['cum_resp%'], label = 'Positive Response')\n",
    "plt.plot([i for i in range(1,11)],ks_table['cum_non_resp%'], label = 'Negative Response')\n",
    "# plt.plot([i for i in range(1,11)], np.arange(0, 110, 10)[1:], label = 'Negative')\n",
    "\n",
    "plt.xticks(np.arange(1, 11), labels=[(str(i)) for i in list(range(1,11))])\n",
    "plt.yticks(np.arange(0, 110, 10), labels=[(str(i)+'0%') for i in list(range(0,11))])\n",
    "\n",
    "plt.title('KS chart')\n",
    "plt.ylabel('Cumulative Responses')\n",
    "plt.xlabel('Deciles')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression - Oversampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = LogisticRegression(max_iter=500)\n",
    "lr2.fit(X_over_train, y_over_train)\n",
    "y_predict= lr2.predict(X_test_orig)\n",
    "classification_report(y_test_orig, y_predict, 'Oversampled', 'Logistic Regression')\n",
    "\n",
    "cross_val_report(lr2, X_over_train, y_over_train)\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(15,5))\n",
    "plot_roc_curve(lr2, X_test_orig, y_test_orig, ax=axs[0])\n",
    "plot_confusion_matrix(lr2, X_test_orig, y_test_orig, cmap='BuPu', ax=axs[1])\n",
    "\n",
    "proba = lr2.predict_proba(X_test_orig)[:,1]\n",
    "axs[2].hist(proba)\n",
    "axs[2].set_title('Probablity of Target=1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test_orig, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank Ordering Stats for Logistic Regression - Oversampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_df = pd.DataFrame(proba, columns=['Probablity'])\n",
    "proba_df['present_decile'] = pd.qcut(proba_df.Probablity, 10, labels=[str(i+1) for i in range(10)])\n",
    "proba_df.present_decile = proba_df.present_decile.astype(int)\n",
    "\n",
    "proba_df['response_test'] = y_test_orig\n",
    "proba_df['response_model'] = proba_df['Probablity'].apply(lambda x: 0 if x<=0.5 else 1)\n",
    "proba_df['correct_loan_prediction'] = 0\n",
    "for ind, row in proba_df.iterrows():\n",
    "    if row['response_test'] == row['response_model'] == 1:\n",
    "        proba_df.loc[ind, 'correct_loan_prediction'] =1\n",
    "\n",
    "\n",
    "ks_table = pd.DataFrame({'Decile':[j for j in range(10,0,-1)]})\n",
    "\n",
    "ks_table['base'] =0\n",
    "ks_table['responses'] =0\n",
    "ks_table['non_responses'] =0\n",
    "for ind, row in ks_table.iterrows():\n",
    "    ks_table.loc[ind, 'base'] = proba_df[proba_df.present_decile==row['Decile']].shape[0]\n",
    "    \n",
    "    try:\n",
    "        correct_loan_prediction1 = proba_df[proba_df.present_decile==row['Decile']].correct_loan_prediction.value_counts()[1]\n",
    "    except:\n",
    "        correct_loan_prediction1 = 0\n",
    "        \n",
    "    ks_table.loc[ind, 'responses'] = correct_loan_prediction1\n",
    "    \n",
    "ks_table['non_responses'] = ks_table['base'] - ks_table['responses']\n",
    "    \n",
    "ks_table['resp_rate'] = ks_table['responses']/ks_table['base']*100\n",
    "ks_table['non_resp_rate'] = ks_table['non_responses']/ks_table['base']*100\n",
    "\n",
    "ks_table['cum_base'] = ks_table.base.cumsum()\n",
    "ks_table['cum_resp'] = ks_table.responses.cumsum()\n",
    "ks_table['cum_non_resp'] = ks_table.non_responses.cumsum()\n",
    "\n",
    "ks_table['cum_resp%'] = ks_table['cum_resp']/ks_table['cum_resp'].max()*100\n",
    "ks_table['cum_non_resp%'] = ks_table['cum_non_resp']/ks_table['cum_non_resp'].max()*100\n",
    "ks_table['ks'] = ks_table['cum_resp%']-ks_table['cum_non_resp%']\n",
    "\n",
    "ks_table['na_label'] = ks_table['cum_resp']/ks_table['cum_base']*100\n",
    "ks_table['lift'] = ks_table['na_label']/(100*ks_table['cum_resp'].max()/ks_table['cum_base'].max())\n",
    "\n",
    "ks_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gain Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(1,11)],ks_table['cum_resp%'], label = 'Targeted Response')\n",
    "plt.plot([i for i in range(1,11)], np.arange(0, 110, 10)[1:], label = 'Random approach')\n",
    "\n",
    "plt.xticks(np.arange(1, 11), labels=[(str(i)+'0%') for i in list(range(0,11))])\n",
    "plt.yticks(np.arange(0, 110, 10), labels=[(str(i)+'0%') for i in list(range(0,11))])\n",
    "\n",
    "plt.title('Gain Chart')\n",
    "plt.ylabel('Cumulative Percentage of Responders Captured')\n",
    "plt.xlabel('Population')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lift Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(1,11)],ks_table.lift*100, label = 'Targeted Response')\n",
    "plt.plot([i for i in range(1,11)], [100, 100, 100, 100, 100, 100, 100, 100, 100, 100], label = 'Random approach')\n",
    "\n",
    "plt.xticks(np.arange(1, 11), labels=[(str(i)) for i in list(range(1,11))])\n",
    "plt.yticks(np.arange(0, 900, 100), labels=[(str(i)+'00%') for i in list(range(0,11))])\n",
    "\n",
    "plt.title('Lift Chart')\n",
    "plt.ylabel('Lift%')\n",
    "plt.xlabel('Decile')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KS chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i for i in range(1,11)],ks_table['cum_resp%'], label = 'Positive Response')\n",
    "plt.plot([i for i in range(1,11)],ks_table['cum_non_resp%'], label = 'Negative Response')\n",
    "# plt.plot([i for i in range(1,11)], np.arange(0, 110, 10)[1:], label = 'Negative')\n",
    "\n",
    "plt.xticks(np.arange(1, 11), labels=[(str(i)) for i in list(range(1,11))])\n",
    "plt.yticks(np.arange(0, 110, 10), labels=[(str(i)+'0%') for i in list(range(0,11))])\n",
    "\n",
    "plt.title('KS chart')\n",
    "plt.ylabel('Cumulative Responses')\n",
    "plt.xlabel('Deciles')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------End of Model Exploration---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRE-BUCKETING VISUALIZATIONS FOR INFERENCES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCR Vs Occupation Vs Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"Occupation\", y=\"SCR\", hue = \"Target\",data=data, kind = \"violin\", split = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inferences: \n",
    "\n",
    "- `SELF-EMP` class tends to have more `SCR` values who are likely to opt for loans.\n",
    "- `SAL` class shows uniformity across `SCR` for people opting/not opting for loans.\n",
    "- `SENP` business class tend to show similar fashion like `SELF-EMP` class when it comes to opting for loans.\n",
    "- `PROF` class tends to lie somewhere between `SENP` and `SAL` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCR Vs Occupation Vs Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(x=\"Occupation\", y=\"SCR\", hue = \"Target\",data=data, aspect=1.5, kind = \"line\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCR Vs Occupation Vs Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"Occupation\", y=\"SCR\", hue = \"Target\",data=data, aspect=2.0, kind = \"point\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inferences: \n",
    "\n",
    "- `SELF-EMP`class, there can be seen a high `SCR` value ranging between 660 to 700 points who have shown interest in opting for loans whereas least interest in the same class was shown at 540 to 550 points of `SCR`\n",
    "\n",
    "- `SENP` class. are the second in line to opt for Loans, as they tend to show comaratively hgiher `SCR` values in the line graph above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bucketing for AGE values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pd.qcut() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['Ageb'] = pd.qcut(data['Age'], q=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AGE Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.Ageb.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.Ageb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(data1, hue='Target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.get_dummies(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age Bucket Ranking Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Ageb_(30.0, 38.0]', 'Ageb_(20.999, 30.0]','Ageb_(46.0, 55.0]','Ageb_(38.0, 46.0]']\n",
    "\n",
    "def func1(x):\n",
    "    if x ==1:\n",
    "        return 1\n",
    "def func2(x):\n",
    "    if x ==1:\n",
    "        return 2\n",
    "\n",
    "def func3(x):\n",
    "    if x ==1:\n",
    "        return 3\n",
    "\n",
    "def func4(x):\n",
    "    if x ==1:\n",
    "        return 4\n",
    "\n",
    "\n",
    "data1['age_d'] = data1['Ageb_(30.0, 38.0]'].apply(func1)\n",
    "data1['age_d'] = data1['Ageb_(20.999, 30.0]'].apply(func2)\n",
    "data1['age_d'] = data1['Ageb_(46.0, 55.0]'].apply(func3)\n",
    "data1['age_d'] = data1['Ageb_(38.0, 46.0]'].apply(func4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, row in data1.iterrows():\n",
    "    if row['Ageb_(20.999, 30.0]'] ==1:\n",
    "        data1.loc[ind, 'age_d'] = 1\n",
    "    elif row['Ageb_(30.0, 38.0]'] ==1:\n",
    "        data1.loc[ind, 'age_d'] = 2\n",
    "    elif row['Ageb_(38.0, 46.0]'] ==1:\n",
    "        data1.loc[ind, 'age_d'] = 3\n",
    "    elif row['Ageb_(46.0, 55.0]'] ==1:\n",
    "        data1.loc[ind, 'age_d'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.age_d.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting Age buckets to integer type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.age_d = data1.age_d.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POST-BUCKETING VISUALIZATIONS FOR INFERENCES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCR Vs Age-Category Vs Target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AGE Intervals & Ranking\n",
    "\n",
    "- (20.9, 30.0]   ----> 1\n",
    "- (30.0, 38.0]   ----> 2\n",
    "- (38.0, 46.0]   ----> 3\n",
    "- (46.0, 55.0]   ----> 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"age_d\", y=\"SCR\", hue = \"Target\",data=data1, kind = \"violin\", split = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"age_d\", y=\"SCR\", hue = \"Target\",data=data1, aspect=2.0, kind = \"point\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inferences: \n",
    "\n",
    "- The `Age groups` `(20.9-30] years` and `(38-46] years` tend to showwcase higher `SCR` values hence more interest towards opting for lonans. However, the age groups (30-38] and (46.0-55) showcase least interest in opting for loans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCR Vs Age-Category Vs Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"age_d\", y=\"SCR\", hue = \"Target\",data=data1, kind = \"swarm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('ticks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUCKETING SCR & HOLDING PERIODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['SCRb'] = pd.qcut(data['SCR'], q=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.SCRb.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['HPB'] = pd.qcut(data['Holding_Period'], q=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.HPB.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCR-Bucketed Vs Age-Category Vs Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"SCRb\", y=\"age_d\", hue = \"Target\",data=data1, kind = \"point\", split = True,)\n",
    "plt.show()\n",
    "plt.figure(figsize=(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.catplot(x=\"age_d\", y=\"SCRb\", hue = \"Target\",data=data1, kind = \"swarm\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"SCRb\", y=\"age_d\", hue = \"Target\",data=data1, kind = \"violin\", split = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inferences: \n",
    "\n",
    "- People in the `Age Group` `(46.0, 55.0]` years tend to have higher `SCR` score i.e. 826 to 1000 points and opt for loans as compared to `(30.0, 38.0]` years who stand at the second position for higher `SCR` values i.e. 650 to 830 points.\n",
    "\n",
    "- People in the `Age Group` `(38.0, 46.0]` years tend to have `SCR` values between 400 to 650 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holding Period Bucketed Vs Age-Category Vs Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"HPB\", y=\"age_d\", hue = \"Target\",data=data1, kind = \"violin\", split = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inferences: \n",
    "\n",
    "- Higher the `Holding Period` more stable is the money in the person's account. \n",
    "- `Holding Period` of 23-31 weeks tends to be uniform across all the `Age Groups`\n",
    "- `Holding Period` between 1-8 weeks tends to lie in the `Age Groups` = 2 and 3 i.e. (30.0, 38.0] and (38.0, 46.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"HPB\", y=\"age_d\", hue = \"Target\",data=data1, kind = \"point\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pair-Plot on Bucketed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(data1, hue = 'Target')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inferences from Pair-Plot: \n",
    "\n",
    "- People who tend to opt for loan have less `BALANCE` w.r.t people not buying loan.\n",
    "- People having higher `BALANCE` tend to be in between 35-50 years of `AGE`.\n",
    "- People having less `BALANCE` tend to show more interest towards loans i.e. higher `SCR` values.\n",
    "- People having less `BALANCE` tend to have higher `No of Credit transactions` opt for loans.\n",
    "- People having less `BALANCE` have higher `HOLDING PERIOD` who opt for loans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----------------------------------------------------Start of Black Box Models Exploration------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP - BlackBox Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_summary = shap.kmeans(X_train_orig, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainerKNN = shap.KernelExplainer(clf_KNN0.predict,X_train_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values_KNN_test = explainerKNN.shap_values(X_test_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# shap.initjs()\n",
    "# shap.force_plot(explainerKNN.expected_value, shap_values_KNN_test[:1000,:], X_test_orig.iloc[:1000,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIME- BlackBox Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lime\n",
    "# import lime.lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb_params = {\n",
    "#   'task': 'train',\n",
    "#     'boosting_type': 'goss',\n",
    "#     'objective': 'binary',\n",
    "#     'metric':'binary_logloss',\n",
    "#     'metric': {'l2', 'auc'},\n",
    "#     'num_leaves': 50,\n",
    "#     'learning_rate': 0.1,\n",
    "#     'feature_fraction': 0.8,\n",
    "#     'bagging_fraction': 0.8,\n",
    "#     'verbose': None,\n",
    "#     'num_iteration':100,\n",
    "#     'num_threads':7,\n",
    "#     'max_depth':12,\n",
    "#     'min_data_in_leaf':100,\n",
    "#     'alpha':0.5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# from lime import submodular_pick\n",
    "# import lightgbm as lgb\n",
    "\n",
    "# lgb_train = lgb.Dataset(X_train_orig, y_train_orig)\n",
    "# lgb_eval = lgb.Dataset(X_test_orig, y_test_orig)\n",
    "\n",
    "# model = lgb.train(lgb_params,lgb_train,num_boost_round=20,valid_sets=lgb_eval,early_stopping_rounds=5)\n",
    "# lime.lime_tabular.LimeTabularExplainer(data[model.feature_name()].astype(int).values,  \n",
    "# mode='classification',training_labels=data3['Target'],feature_names=model.feature_name())\n",
    "# # Remember to convert the dataframe to matrix values\n",
    "# # SP-LIME returns exaplanations on a sample set to provide a non redundant global decision boundary of original model\n",
    "# sp_obj = submodular_pick.SubmodularPick(explainer,data3[model.feature_name()].values, \\\n",
    "# prob, num_features=5,num_exps_desired=10)\n",
    "\n",
    "# [exp.as_pyplot_figure(label=1) for exp in sp_obj.sp_explanations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from catboost import CatBoostClassifier\n",
    "# model = CatBoostClassifier(random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cate_features_index = np.where(data.dtypes != float)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_over_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_under_train,y_under_train,cat_features=cate_features_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = pd.read_csv(\"test_data.csv\")\n",
    "# pred = model.predict(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix(y_test_orig, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----------------------------------------------------End of Black Box Models Exploration------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Matrix - Which Models to be Considered?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval = {'Good Fit Percent%': ['10.9','9.84','19.6','17.2','8.6','18.4','11.4','25.0','25.0','16.4','20.8','17.2'],\n",
    "        'Comments': ['Not Considering','Not Considering','Not Considering','Not Considering','Not Considering','Not Considering',\n",
    "                     'Not Considering','Considering','Considering','Not Considering','Considering','Not Considering',]\n",
    "        }\n",
    "\n",
    "df1 = pd.DataFrame(model_eval, columns = ['Good Fit Percent%','Comments'], index=['DecisionTreeClassifier - Original Data','DecisionTreeClassifier - UnderSampled Data','DecisionTreeClassifier - OverSampled Data',\n",
    "                                                                           'KNN Classifier - Original Data','KNN Classifier - Undersampled Data','Random Forest Classifier - Original Data','RandomForest Classifier - Undersampled Data',\n",
    "                                                                           'RandomForest Classifier - Oversampled Data','Logistic Regression - Original Data','Logistic Regression - Undersampled Data',\n",
    "                                                                          'Logistic Regression - Oversampled Data','KNN Classifier - Oversampled Data'])\n",
    "\n",
    "print (df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_excel(\"F:\\\\IBPA_IIM_FinalProject\\\\data1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = data._get_numeric_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X_original.values, i) for i in range(X_original.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif[\"features\"] = X_original.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn import tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth = 5)\n",
    "clf.fit(X_train_orig, y_train_orig)\n",
    "y_prediction_orig = clf.predict(X_test_orig)\n",
    "classification_report(y_test_orig, y_prediction_orig, 'Original', 'Decision Tree')\n",
    "plot_roc_curve(clf, X_test_orig, y_test_orig)\n",
    "plt.show()\n",
    "# cross_val_report(clf, y_test_orig,y_under_prediction.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_o = DecisionTreeClassifier(max_depth = 5)\n",
    "clf_o.fit(X_over_train, y_over_train)\n",
    "y_prediction_over = clf_o.predict(X_over_train)\n",
    "classification_report(y_over_test, y_prediction_over, 'OverSampled', 'Decision Tree')\n",
    "plot_roc_curve(clf_o, X_over_test, y_over_test)\n",
    "plt.show()\n",
    "# cross_val_report(clf, y_test_orig,y_under_prediction.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_u = DecisionTreeClassifier(max_depth = 5)\n",
    "clf_u.fit(X_under_train, y_under_train)\n",
    "y_prediction_under = clf_u.predict(X_under_train)\n",
    "classification_report(y_under_test, y_prediction_under, 'UnderSampled', 'Decision Tree')\n",
    "plot_roc_curve(clf_u, X_under_test, y_under_test)\n",
    "plt.show()\n",
    "# cross_val_report(clf, y_test_orig,y_under_prediction.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(50,20), dpi = 800)\n",
    "# tree.plot_tree(clf, \n",
    "#                    feature_names=X_original.columns.tolist(),  \n",
    "#                    class_names=['0','1'],\n",
    "#                    filled=True, fontsize=10)\n",
    "\n",
    "# print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = df2.iloc[:,1:]\n",
    "target_names = df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (5,5), dpi = 800)\n",
    "\n",
    "# tree.plot_tree(clf,feature_names = list(feature_names), \\\n",
    "#               class_names = [\"0\", \"1\"], proportion = True, \\\n",
    "#                filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install graphviz\n",
    "\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn import datasets\n",
    "# from IPython.display import Image  \n",
    "# from sklearn import tree\n",
    "# import pydotplus\n",
    "\n",
    "# dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "#                                 feature_names=list(feature_names.columns),  \n",
    "# #                                 class_names=iris.target_names\n",
    "#                                )\n",
    "\n",
    "# # Draw graph\n",
    "# graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "\n",
    "# # Show graph\n",
    "# print(graph)\n",
    "# Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the rules of all the nodes\n",
    "plt.figure(figsize = None, dpi = 800)\n",
    "tree_rules = tree.export_text(clf,  feature_names = list(feature_names))\n",
    "print(tree_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (5,5), dpi = 800)\n",
    "\n",
    "# feature_names = df.drop(\"left\", axis =1).columns\n",
    "\n",
    "# tree.plot_tree(clf,feature_names = feature_names.tolist(), \\\n",
    "#               class_names = [\"stayed\", \"left\"], proportion = True, \\\n",
    "#                filled = True)\n",
    "\n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_representation = tree.export_text(clf)\n",
    "# print(text_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import _tree\n",
    "\n",
    "# def tree_to_code(tree, feature_names):\n",
    "\n",
    "# \t'''\n",
    "# \tOutputs a decision tree model as a Python function\n",
    "\t\n",
    "# \tParameters:\n",
    "# \t-----------\n",
    "# \ttree: decision tree model\n",
    "# \t\tThe decision tree to represent as a function\n",
    "# \tfeature_names: list\n",
    "# \t\tThe feature names of the dataset used for building the decision tree\n",
    "# \t'''\n",
    "\n",
    "# \ttree_ = tree.tree_\n",
    "# \tfeature_name = [\n",
    "# \t\tfeature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "# \t\tfor i in tree_.feature\n",
    "# \t]\n",
    "# \tprint(\"def tree({}):\".format(\", \".join(feature_names)))\n",
    "\n",
    "# \tdef recurse(node, depth):\n",
    "# \t\tindent = \"  \" * depth\n",
    "# \t\tif tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "# \t\t\tname = feature_name[node]\n",
    "# \t\t\tthreshold = tree_.threshold[node]\n",
    "# \t\t\tprint(\"{}if {} <= {}:\".format(indent, name, threshold))\n",
    "# \t\t\trecurse(tree_.children_left[node], depth + 1)\n",
    "# \t\t\tprint(\"{}else:  # if {} > {}\".format(indent, name, threshold))\n",
    "# \t\t\trecurse(tree_.children_right[node], depth + 1)\n",
    "# \t\telse:\n",
    "# \t\t\tprint(\"{}return {}\".format(indent, tree_.value[node]))\n",
    "\n",
    "# \trecurse(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import _tree\n",
    "\n",
    "# tree_to_code(df2, list(X_original))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------End of Capstone---------------------------------------------------------------------\n",
    "-----------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
