{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Problem:\n",
    "A group of customers were given an offer in person that they can get a loan at discounted rate and\n",
    "processing fee will be waived off. A pilot campaign was conducted to get response from customers\n",
    "whether they are interested in taking out a loan or not. Response was recorded and data was collected.\n",
    "Based on data given we need to\n",
    "\n",
    "- [x] Build a model to predict whether customers will be interested in taking out a loan or not.\n",
    "- [ ] Identifying features which are most important\n",
    "- [ ] In case of black box models e.g. Random forest use SHAP, LIME to figure out features affecting the target variable\n",
    "- [ ] Approaching a customer has costs involved with it, hence find the profitable segments so that more customized marketing can be done.\n",
    "- [ ] Model will be needed on a monthly basis as this data gets updated each month.\n",
    "\n",
    "Variables involved: `Customer_id`, `Age`, `Gender`, `Balance`, `Occupation`, `No of Credit transaction`, `SCR`, `Holding period`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Questions for the External Mentor\n",
    "\n",
    "\n",
    "- [ ] `Holding Period` (units of measurement months/years)\n",
    "- [ ] `Balance` units of measurement and is it current balance/quarterly etc?\n",
    "- [ ] `SCR` Solvency Capital Requirement explain in detail\n",
    "- [ ] `No. of Credit Transactions` meaning?\n",
    "- [ ] `O` in `Gender` columnn, does it mean null value?\n",
    "- [ ] What do the values in `Occupation` stand for `SELF-EMP`, `SAL`, `SENP`, `PROF`?\n",
    "- [ ] Need a summary of what is going on\n",
    "- [ ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCR propensity of a customer to respond to a digital marketing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Changes v6:\n",
    "1. Now All Models measure recall on same testing data\n",
    "\n",
    "2. Fixed Sampling mistake\n",
    "\n",
    "3. Redefined `print_classification_report` as `classification_report` for better clarity and ease of use\n",
    "\n",
    "4. Visualized Decision Trees\n",
    "\n",
    "5. Implemented SVC\n",
    "\n",
    "6. Implemented KNN which provided great results with default parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Changes v7:\n",
    "1. Fit Random Forest Models\n",
    "\n",
    "2. Fit XgBoost Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: unknown command \"!install\" - maybe you meant \"install\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip -install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f4137b6dd25b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Model_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Balance = data.Balance.astype('int32') #Truncating decimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.Balance<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Balance.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Gender` and `Occupation` are categorical varibles stored as object type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Strong correlations measured except for mild ones in `Holding_period` and other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.corr(), annot=True, square=True) # No strong correlations seen overall\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(data)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = data.Gender)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Gender.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Occupation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Gender.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(data.Gender[data.Gender== 'O'].index, axis = 0, inplace= True) # Removed 196 rows with `Gender` = 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Balance.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(data.Age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = data.Occupation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=data.Target, hue=data.Occupation) ## Self employed are much more likely to take loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data, col='Occupation', hue=\"Gender\")\n",
    "plt.grid(True)\n",
    "g.map(sns.countplot, \"Gender\", alpha=1)\n",
    "g.add_legend()\n",
    "plt.grid((False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(data.No_OF_CR_TXNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.No_OF_CR_TXNS.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x=data.No_OF_CR_TXNS)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(data[data.No_OF_CR_TXNS==0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.drop(index=data[data.No_OF_CR_TXNS==0].index, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.displot(data.SCR, kind = 'kde')\n",
    "sns.distplot(data.SCR)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.SCR.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(data.Holding_Period)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### End of Exploratory Data Analysis\n",
    "-----------\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Create a function for easy report printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class for pretty printing\n",
    "class color:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'\n",
    "    \n",
    "# function for validation on test data   \n",
    "def classification_report(y_true, y_prediction, type_of_data='Enter Over/Under/Original sampled', type_of_classifier='ClassifierName'):\n",
    "    \"\"\"Print Classification report\"\"\"\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_prediction)\n",
    "    precision = precision_score(y_true, y_prediction)\n",
    "    recall = recall_score(y_true, y_prediction)\n",
    "    f1 = f1_score(y_true, y_prediction)\n",
    "    \n",
    "    print('Classification Report on Testing Data:\\n'+ color.BOLD + type_of_data, 'data\\n'+color.END+color.RED+color.BOLD+type_of_classifier,'Classifier'+color.END+color.END)\n",
    "    print()\n",
    "    print('---------------------------------------')\n",
    "    print(color.BOLD + 'Recall: %s' %recall + color.END)\n",
    "    print('Precision: %s' %precision)\n",
    "    print('F1 score: %s' %f1)\n",
    "    print('Accuracy: %s' %accuracy)\n",
    "    print('---------------------------------------')\n",
    "    print()\n",
    "\n",
    "\n",
    "# A function for cross-validation report    \n",
    "def cross_val_report(classifier, train_data, train_label, cv=10, scoring=['recall','precision', 'f1','accuracy']):\n",
    "    \n",
    "    score = cross_validate(classifier, train_data, train_label, cv=cv, scoring= scoring)\n",
    "    recall = np.mean(score['test_recall'])\n",
    "    precision = np.mean(score['test_precision'])\n",
    "    f1 = np.mean(score['test_f1'])\n",
    "    accuracy= np.mean(score['test_accuracy'])\n",
    "    print('Cross Validation Report')\n",
    "    print(color.BOLD + 'Recall: %s' %recall + color.END)\n",
    "    print('Precision: %s' %precision)\n",
    "    print('F1: %s' %f1)\n",
    "    print('Accuracy: %s' %accuracy)\n",
    "    print()\n",
    "    print(\"*Mean values presented\")\n",
    "    print('---------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the first set of training and test data on imbalanced data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data, columns=['Gender','Occupation'], drop_first = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Creating a model with Original Unbalanced data and measuring metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_original = df.iloc[:,1:]\n",
    "y_original = df.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(X_original,y_original, shuffle = ['True'], stratify=y_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth = 5)\n",
    "clf.fit(X_train_orig, y_train_orig)\n",
    "y_prediction_orig = clf.predict(X_test_orig)\n",
    "classification_report(y_test_orig, y_prediction_orig, 'Original', 'Decision Tree')\n",
    "# cross_val_report(clf, y_test_orig,y_under_prediction.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(50,20))\n",
    "_ = plot_tree(clf, \n",
    "                   feature_names=list(X_original.columns),  \n",
    "                   class_names=['0','1'],\n",
    "                   filled=True, fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Create undersampled data and fit a model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_under_train, y_under_train = NearMiss().fit_resample(X_train_orig, y_train_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.Target==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_under_train.shape, y_under_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_under_sampled = DecisionTreeClassifier(max_depth = 5)\n",
    "clf_under_sampled.fit(X_under_train, y_under_train)\n",
    "y_under_prediction = clf_under_sampled.predict(X_test_orig)\n",
    "classification_report(y_test_orig,y_under_prediction, 'Undersampled', 'Decision Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_val_report(clf_under_sampled, y_test_orig,y_under_prediction)\n",
    "\n",
    "## crossval here causes unbalanced split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(100,100))\n",
    "_ = plot_tree(clf_under_sampled, \n",
    "                   feature_names=list(X_original.columns),  \n",
    "                   class_names=['0','1'],\n",
    "                   filled=True, fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Model on  an oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_over_train, y_over_train = SMOTE().fit_resample(X_original, y_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_over_sampled = DecisionTreeClassifier(max_depth = 5)\n",
    "clf_over_sampled.fit(X_over_train, y_over_train)\n",
    "y_over_predict = clf_over_sampled.predict(X_test_orig)\n",
    "classification_report(y_test_orig, y_over_predict, 'Oversampled', 'Decision Tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(100,100))\n",
    "_ = plot_tree(clf_over_sampled, \n",
    "                   feature_names=list(X_original.columns),  \n",
    "                   class_names=['0','1'],\n",
    "                   filled=True, fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original:     \"+color.BOLD+ \"X_original,y_original\"+color.END+\"::  X_train_orig, X_test_orig, y_train_orig, y_test_orig\")\n",
    "print()\n",
    "print(\"Undersampled:\"+color.BOLD+ \" X_under, y_under\"+color.END+\"     ::  X_under_train, y_under_train\")\n",
    "print()\n",
    "print(\"Oversampled:\"+color.BOLD+ \"  X_over, y_over\"+color.END+\"       ::  X_over_train, y_over_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above datasets can be better sampled by adjusting hyper-parameters of NearMiss and SMOTE, or other methods of sampling could be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifiers applied\n",
    "\n",
    "*SVC fails to fit on original dataset, possibly because of unbalance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc0 = SVC()\n",
    "\n",
    "clf_svc0.fit(X_under_train, y_under_train)\n",
    "y_predict = clf_svc0.predict(X_test_orig)\n",
    "classification_report(y_test_orig, y_predict, 'Undersampled', 'SVM')\n",
    "cross_val_report(clf_svc0, X_under_train, y_under_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Will take LONG Time for Training\n",
    "# clf_svc1 = SVC()\n",
    "# clf_svc1.fit(X_over_train, y_over_train)\n",
    "# y_predict = clf_svc1.predict(X_test_orig)\n",
    "# classification_report(y_test_orig, y_predict, 'Oversampled', 'SVM')\n",
    "# cross_val_report(clf_svc1, X_under_train, y_under_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_KNN0 = KNeighborsClassifier()\n",
    "clf_KNN0.fit(X_train_orig, y_train_orig)\n",
    "y_predict= clf_KNN0.predict(X_test_orig)\n",
    "classification_report(y_test_orig, y_predict, 'Original', 'KNN')\n",
    "cross_val_report(clf_KNN0, X_under_train, y_under_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_KNN1 = KNeighborsClassifier()\n",
    "clf_KNN1.fit(X_under_train, y_under_train)\n",
    "y_predict= clf_KNN1.predict(X_test_orig)\n",
    "classification_report(y_test_orig, y_predict, 'Undersampled', 'KNN')\n",
    "cross_val_report(clf_KNN1, X_under_train, y_under_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_KNN2 = KNeighborsClassifier()\n",
    "clf_KNN2.fit(X_over_train, y_over_train)\n",
    "y_predict= clf_KNN2.predict(X_test_orig)\n",
    "classification_report(y_test_orig, y_predict, 'Oversampled', 'KNN')\n",
    "cross_val_report(clf_KNN2, X_under_train, y_under_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf0 = RandomForestClassifier()\n",
    "clf_rf0.fit(X_train_orig, y_train_orig)\n",
    "y_predict= clf_rf0.predict(X_test_orig)\n",
    "classification_report(y_test_orig, y_predict, 'Original', 'Random Forest')\n",
    "cross_val_report(clf_rf0, X_under_train, y_under_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf1 = RandomForestClassifier()\n",
    "clf_rf1.fit(X_under_train, y_under_train)\n",
    "y_predict= clf_rf1.predict(X_test_orig)\n",
    "classification_report(y_test_orig, y_predict, 'Undersampled', 'Random Forest')\n",
    "cross_val_report(clf_rf1, X_under_train, y_under_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf2 = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf2.fit(X_under_train, y_under_train)\n",
    "y_predict= clf_rf2.predict(X_test_orig)\n",
    "classification_report(y_test_orig, y_predict, 'Oversampled', 'Random Forest')\n",
    "cross_val_report(clf_rf2, X_under_train, y_under_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing training and testing data to DMatrix types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_orig_DM = xgb.DMatrix(X_train_orig, label= y_train_orig)\n",
    "train_under_DM = xgb.DMatrix(X_under_train, label= y_under_train)\n",
    "train_over_DM = xgb.DMatrix(X_over_train, label= y_over_train)\n",
    "\n",
    "test_DM = xgb.DMatrix(X_test_orig, label= y_test_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'max_depth': 5,\n",
    "    'eta': 0.1,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 3\n",
    "}\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cl0 = xgb.train(param, train_orig_DM, epochs)\n",
    "predictions = xgb_cl0.predict(test_DM)\n",
    "classification_report(y_test_orig, predictions, 'Original', 'XgBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cl1 = xgb.train(param, train_under_DM, epochs)\n",
    "predictions = xgb_cl1.predict(test_DM)\n",
    "classification_report(y_test_orig, predictions, 'Undersampled', 'XgBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cl2 = xgb.train(param, train_over_DM, epochs)\n",
    "predictions = xgb_cl2.predict(test_DM)\n",
    "classification_report(y_test_orig, predictions, 'Oversampled', 'XgBoost')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
